{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 19:40:45.659336: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-17 19:40:53.550122: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch as t\n",
    "import os\n",
    "import wandb\n",
    "from VLM_base_classes import *\n",
    "from models import load_model\n",
    "from config import PATH_TO_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DeepSeek_VL'\n",
    "model, processor = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmodel_name\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepSeek_VL\u001b[39m\u001b[38;5;124m'\u001b[39m: \n\u001b[1;32m      2\u001b[0m     baseclass \u001b[38;5;241m=\u001b[39m DeepSeekVLBaseClass\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLlaVa\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "if model_name == 'DeepSeek_VL': \n",
    "    baseclass = DeepSeekVLBaseClass\n",
    "elif model_name == 'LlaVa':\n",
    "    baseclass = LlavaBaseClass\n",
    "    \n",
    "baseline = baseclass(cfg=None, model=model, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(PATH_TO_DATASETS, 'advbench_mini_train.csv'), index_col=0)\n",
    "df_test = pd.read_csv(os.path.join(PATH_TO_DATASETS, 'advbench_mini_test.csv'), index_col=0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()\n",
    "df_test_copy = df_test.copy()\n",
    "\n",
    "df_train_copy['baseline_automatic'] = ''\n",
    "df_test_copy['baseline_automatic'] = ''\n",
    "df_train_copy['baseline_manual'] = ''\n",
    "df_test_copy['baseline_manual'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 500\n",
    "\n",
    "run = wandb.init(project='datasets', job_type='upload_dataset')\n",
    "baselines_artifact = wandb.Artifact('baselines_advbench_mini', type='baselines')\n",
    "\n",
    "for ind in df_test.index:\n",
    "    prompt = df_test.loc[ind, 'goal']\n",
    "    _, answer = baseline.generate_autoregressive(prompt=prompt, image=None, max_new_tokens=max_new_tokens, no_eos_token=False)\n",
    "    _, answer_manual = baseline.generate_autoregressive_manual(prompt=prompt, image=None, use_cache=False, max_new_tokens=max_new_tokens, no_eos_token=False)\n",
    "\n",
    "    df_test_copy.loc[ind, 'baseline_automatic'] = answer\n",
    "    df_test_copy.loc[ind, 'baseline_manual'] = ''.join(answer_manual)\n",
    "\n",
    "table_scores_test = wandb.Table(dataframe=df_test_copy)\n",
    "baselines_artifact.add(table_scores_test, name='baselines_test')\n",
    "\n",
    "for ind in df_train.index:\n",
    "    prompt = df_train.loc[ind, 'goal']\n",
    "    _, answer = baseline.generate_autoregressive(prompt=prompt, image=None, max_new_tokens=max_new_tokens, no_eos_token=False)\n",
    "    _, answer_manual = baseline.generate_autoregressive_manual(prompt=prompt, image=None, use_cache=False, max_new_tokens=max_new_tokens, no_eos_token=False)\n",
    "\n",
    "    df_train_copy.loc[ind, 'baseline_automatic'] = answer\n",
    "    df_train_copy.loc[ind, 'baseline_manual'] = ''.join(answer_manual)\n",
    "\n",
    "table_scores_train = wandb.Table(dataframe=df_train_copy)\n",
    "baselines_artifact.add(table_scores_train, name='baselines_train')\n",
    "\n",
    "run.log_artifact(baselines_artifact)\n",
    "run.finish()\n",
    "\n",
    "path_to_results = os.path.join(path_to_datasets, 'results')\n",
    "df_train_copy.to_csv(os.path.join(path_to_results, 'advbench_mini_train_baseline.csv'))\n",
    "df_test_copy.to_csv(os.path.join(path_to_results, 'advbench_mini_test_baseline.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
