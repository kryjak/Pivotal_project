{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as t\n",
    "from models import load_model\n",
    "from attacks import ControlSingleTokenAttack, ControlMultipleTokensAttack, JailbreakAttack\n",
    "# from data import load_dataset\n",
    "from config import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from custom_image_transforms import CustomTransforms\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q einops attrdict3 wandb llava\n",
    "%pip list | grep transformers\n",
    "%pip list | grep bitsandbytes\n",
    "%pip list | grep accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=WANDB_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, processor = load_model(MODEL)\n",
    "# train_data, test_data = load_dataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == 'DeepSeek-VL':\n",
    "    from VLM_base_classes import DeepSeekVLBaseClass\n",
    "\n",
    "    img_size = processor.image_processor.image_size\n",
    "\n",
    "    base_model_class = DeepSeekVLBaseClass\n",
    "    attack_config = attack_config_DeepSeek + wandb_config\n",
    "elif MODEL == 'LLaVa':\n",
    "    from VLM_base_classes import LlavaBaseClass\n",
    "\n",
    "    img_size = model.config.vision_config.image_size\n",
    "    model.config.image_grid_pinpoints.append([img_size, img_size])\n",
    "    print('LLaVa grid points: ', model.config.image_grid_pinpoints)\n",
    "\n",
    "    base_model_class = LlavaBaseClass\n",
    "    attack_config = attack_config_Llava + wandb_config\n",
    "else:\n",
    "    raise NotImplementedError(f'Model {MODEL} not implemented yet.')\n",
    "\n",
    "base_instance = base_model_class(attack_config, model, processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put model in eval mode and switch off gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "\n",
    "if model.training:\n",
    "    print('Model is in training mode')\n",
    "else:\n",
    "    print('Model is in eval mode')\n",
    "\n",
    "# we're only interested in computing the gradients wrt the input images, not the internal parameters\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the processor so that we can pre-process the prompt+image into a format accepted by the model. This includes a normalisation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = processor.tokenizer\n",
    "\n",
    "processor_mean = t.tensor(processor.image_processor.image_mean).to(DEVICE)\n",
    "processor_std = t.tensor(processor.image_processor.image_std).to(DEVICE)\n",
    "print(f'{processor_mean=}')\n",
    "print(f'{processor_std=}')\n",
    "\n",
    "print(f'{img_size=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://wp.inews.co.uk/wp-content/uploads/2023/03/SEI_149780351.jpg?crop=157px%2C0px%2C1537px%2C1537px&resize=640%2C640\"\n",
    "img_path = os.path.join(os.getcwd(), 'test_image.jpg')\n",
    "\n",
    "img = open_image_from_url(img_url)\n",
    "img_size = 100\n",
    "img = img.resize((img_size, img_size))\n",
    "img.save(img_path)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"What is shown in this image?\"\n",
    "test_target = \"dog\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-token attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this attack, we are optimising using only a single target output token, e.g. 'dog'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_token_attack = ControlSingleTokenAttack(base_instance, attack_config, wandb_name='single_token')\n",
    "init_image, delta, loss_train = single_token_attack.train_attack(test_prompt, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can import saved data from wandb with:\n",
    "# api = wandb.Api()\n",
    "# wandb_run = api.run(run_path)\n",
    "# wandb_run.file('sample_data/' + 'init_image.pt' ).download(replace=True)\n",
    "# loaded_tensor = t.load(\"sample_data/init_image.pt\")\n",
    "# assert t.equal(init_image, loaded_tensor) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard way to execute the attack is to suply the initial image and the perturbation `delta`. Both will be tensors: `image` is in the range $[0.0, 1.0]$, `delta` might spill outside of the range $[-1.0, 1.0]$ and is clamped within the function call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the default processing pipeline with autoregressive generation\n",
    "# max_new_tokens is set to 10\n",
    "output, answer = single_token_attack.execute_attack(prompt=test_prompt, image=init_image, delta=delta, \n",
    "                                                    max_new_tokens=10, no_eos_token=True,\n",
    "                                                    do_sample=True, top_p=0.95, top_k=20)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can supply an adversarial image (inital + perturbation). This needs to be a tensor in the range $[0, 255.0]$ and the perturbation needs to be clamped manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_image = (init_image + attack_config.eps*delta.clamp(-1, 1)).clamp(0, 1) * 255\n",
    "\n",
    "output_v2, answer_v2 = single_token_attack.execute_attack(prompt=test_prompt, \n",
    "                                                        adversarial_image=adversarial_image, \n",
    "                                                        max_new_tokens=10, no_eos_token=True, \n",
    "                                                        do_sample=True, top_p=0.95, top_k=20)\n",
    "print(answer_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_token_attack.finish_wandb_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-token attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this attack, we are optimising using multiple target output tokens, e.g. ['dog', 'on', 'a', 'bike']. For this reason, we introduce two training methods:\n",
    "- 'autogregressive' -- using a prompt of length $n$, we generate the prediction for token in the $n+1$ position. This new token is appended to the original prompt, and now the new prompt of length $n+1$ is used to generate another token at position $n+2$. This proceeds recursively until we run out of target tokens.\n",
    "- 'teacher_forcing' -- we append the actualy target tokens to the starting prompt, no matter if these were the actual tokens generated by the model or not. This method is supposed to smoothen out the loss curve by `keeping the model on track' despite prediction errors. The name ocmes from a scenario where a school teacher allows the student to view the correct answer in the first part of the test (even though the student was not able to solve this part), so that they can still attempt the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_token_attack = ControlMultipleTokensAttack(base_instance, attack_config, wandb_name='autoregressive')\n",
    "# init_image, delta, loss_train = multi_token_attack.train_attack(prompt, img, training_method='teacher_forcing')\n",
    "init_image, delta, loss_train = multi_token_attack.train_attack(test_prompt, img, training_method='autoregressive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also two generation methods:\n",
    "- 'automatic' -- we use the model's autoregressive generation method.\n",
    "- 'manual' -- we manually generate the next token in the sequence using the model's logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, answer = multi_token_attack.execute_attack(test_prompt, init_image, delta,\n",
    "                                                   generation_method='automatic', max_new_tokens=5, no_eos_token=True,\n",
    "                                                   do_sample=True, top_p=0.95, top_k=20)\n",
    "print(answer)\n",
    "logits, answer = multi_token_attack.execute_attack(test_prompt, init_image, delta,\n",
    "                                                   generation_method='manual', max_new_tokens=5, no_eos_token=True,\n",
    "                                                    do_sample=True, top_p=0.95, top_k=20)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_token_attack.finish_wandb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jailbreaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading data from a previous run, supply the run name in the following format:\n",
    "# wandb_run_name = 'kryjak-None/pivotal_adv_attacks/nepwz08b'\n",
    "# wandb_run_id = wandb_run_name.split('/')[-1]\n",
    "# load_data_from_wandb(wandb_run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb_api = wandb.Api()\n",
    "# run = wandb_api.run(wandb_run_name)\n",
    "# print(run.summary)\n",
    "# print(run.config)\n",
    "# history = run.history()\n",
    "# print(history.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artifact = wandb_api.artifact('kryjak-None/pivotal_adv_attacks/jailbreak_data:v3')\n",
    "# artifact.download(path_prefix=\"jailbreak_completions\")\n",
    "# test_table = artifact.get(\"jailbreak_completions\")\n",
    "# df = pd.DataFrame(data=test_table.data, columns=test_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(PATH_TO_DATASETS, 'advbench_mini_train.csv'), index_col=0)\n",
    "df_test = pd.read_csv(os.path.join(PATH_TO_DATASETS, 'advbench_mini_test.csv'), index_col=0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts\n",
    "train_goals = df_train['goal'].to_list()\n",
    "test_goals = df_test['goal'].to_list()\n",
    "train_goal_single = train_goals[:1]\n",
    "test_goal_single = test_goals[:1]\n",
    "# targets\n",
    "train_targets = df_train['target'].to_list()\n",
    "test_targets = df_test['target'].to_list()\n",
    "# targets need to be tokenized: [[str1, str2,...], [str1, str2,...], ...]\n",
    "train_targets_tokenized = [[tokenizer.decode(token) for token in tokenizer.encode(target, add_special_tokens=False)] for target in train_targets]\n",
    "test_targets_tokenized = [[tokenizer.decode(token) for token in tokenizer.encode(target, add_special_tokens=False)] for target in test_targets]\n",
    "train_target_tokenized_single = train_targets_tokenized[0]\n",
    "test_target_tokenized_single = test_targets_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jailbreak_attack = JailbreakAttack(base_instance, jailbreak_config + wandb_config,wandb_name='test')\n",
    "\n",
    "delta, loss_train = jailbreak_attack.train(\n",
    "                                          prompts=train_goal_single,\n",
    "                                        #   prompts=train_goals,\n",
    "                                          images=[img],\n",
    "                                        targets=train_target_tokenized_single,\n",
    "                                        #   targets=train_targets_tokenized,\n",
    "                                          training_method='teacher_forcing',\n",
    "                                          use_cache=False,\n",
    "                                          batch_size=1,\n",
    "                                          )\n",
    "\n",
    "max_memory_used = t.cuda.max_memory_allocated() / 1024**3\n",
    "wandb.log({'max_memory_used': max_memory_used})\n",
    "print(f'Max memory used during the run: {max_memory_used} GB')\n",
    "t.cuda.reset_peak_memory_stats()\n",
    "\n",
    "jailbreak_attack.finish_wandb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, answer_auto_pil = jailbreak_attack.execute(prompt=test_goals[0], image=None, delta=delta, generation_method='automatic_with_pil', max_new_tokens=7, no_eos_token=False, do_sample=True, top_p=0.95, top_k=20)\n",
    "_, answer_auto = jailbreak_attack.execute(prompt=test_goals[0], image=None, delta=delta, generation_method='automatic', max_new_tokens=7, no_eos_token=False, do_sample=True, top_p=0.95, top_k=20)\n",
    "_, answer_manual = jailbreak_attack.execute(prompt=test_goals[0], image=None, delta=delta, generation_method='manual', max_new_tokens=7, no_eos_token=True, use_cache=False, do_sample=True, top_p=0.95, top_k=20)\n",
    "\n",
    "print(answer_auto_pil)\n",
    "print('----------------------')\n",
    "print(answer_auto)\n",
    "print('----------------------')\n",
    "print(''.join(answer_manual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, answer_auto_pil = jailbreak_attack.execute_with_clamp(prompt=test_goals[1],\n",
    "                                                        image=None,\n",
    "                                                        delta=delta, \n",
    "                                                        generation_method='automatic_with_pil', \n",
    "                                                        max_new_tokens=500, \n",
    "                                                        no_eos_token=True, \n",
    "                                                        do_sample=True, \n",
    "                                                        top_k=2, \n",
    "                                                        # top_k=50, \n",
    "                                                        # top_p=0.95,\n",
    "                                                        no_repeat_ngram_size=6)\n",
    "\n",
    "_, answer_auto = jailbreak_attack.execute_with_clamp(prompt=test_goals[1],\n",
    "                                                    image=None,\n",
    "                                                    delta=delta, \n",
    "                                                    generation_method='automatic', \n",
    "                                                    max_new_tokens=500, \n",
    "                                                    no_eos_token=True, \n",
    "                                                    do_sample=True, \n",
    "                                                    top_k=2, \n",
    "                                                    no_repeat_ngram_size=6)\n",
    "\n",
    "print(answer_auto_pil)\n",
    "print('----------------------')\n",
    "print(answer_auto)\n",
    "print('----------------------')\n",
    "# print(''.join(answer_manual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = {'noise_strength': 1e-1,\n",
    "                'max_jitter_ratio': 0.01,\n",
    "                'contrast_range': (0.9, 1.1),\n",
    "                'sharpness_factor': 'random',\n",
    "                'grayscale_prob': 0.1,\n",
    "                'seed': 42}\n",
    "\n",
    "transform = CustomTransforms(**augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = transforms.ToTensor()(img).to(t.bfloat16).to(DEVICE).requires_grad_(True)\n",
    "transformed_image = transform(test_image)\n",
    "transforms.ToPILImage()(transformed_image.detach().cpu().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_attack = JailbreakAttack(jailbreak_config + wandb_config, model, processor, wandb_run_id=wandb_run_id, wandb_name='augmentations')\n",
    "augmentation_attack.test_dataset(delta=delta, df_test=df_train, max_new_tokens=500, no_eos_token=False, use_cache=False, do_sample=True, top_k=2, no_repeat_ngram_size=6)\n",
    "# augmentation_attack.eval_dataset(max_new_tokens=100, no_eos_token=True, use_cache=False, do_sample=True, top_k=2, no_repeat_ngram_size=6)\n",
    "augmentation_attack.finish_wandb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = transforms.ToTensor()(img).to(t.bfloat16).to(DEVICE).requires_grad_(True)\n",
    "optimizer = t.optim.AdamW([test_image], lr=1e-1, weight_decay=0.0)\n",
    "\n",
    "losses = []\n",
    "for step in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    # print .grad values for one transformation at a time\n",
    "\n",
    "    # transformed_image = test_image\n",
    "    transformed_image = transform(test_image)\n",
    "    loss = transformed_image.std()\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    if step % 10 == 0:\n",
    "        # print(f'Grad norm: {test_image.grad.mean().item()}')\n",
    "        print(f'loss = {loss}')\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'max_memory_used': max_memory_used})\n",
    "print(f'Max memory used during the run: {max_memory_used} GB')\n",
    "wandb.log({'augmentations': augmentations})\n",
    "t.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(transformed_image.detach().cpu().float())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
